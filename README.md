Данный инструмент автоматизирует проектирование исследований биоэквивалентности (БЭ) в соответствии с Решением №85 ЕАЭС. Он выполняет:
- Поиск литературы в PubMed по INN препарата.
- Извлечение фармакокинетических параметров (CVintra, T½) с помощью локальной LLM (Ollama).
- Расчёт размера выборки для 2x2 кроссовер-дизайна с учётом dropout.
- Генерацию структурированного синопсиса протокола в формате .docx на основе шаблона.

## Требования
- Python 3.9+
- Установленная и запущенная [Ollama](https://ollama.com) с моделью `mistral`
- Библиотеки из `requirements.txt`

## 1. Общая архитектура
Приложение построено на фреймворке Streamlit и состоит из нескольких независимых модулей, взаимодействующих через главный файл `main.py`.

## 2. Модули

### 2.1. `config.py`
Содержит настройки:
- `HF_MODEL` – имя локальной модели (по умолчанию `mistral`).
- `PUBMED_EMAIL` – email для доступа к PubMed E-utilities.

### 2.2. `pubmed_search.py`
- Использует библиотеку Biopython для поиска аннотаций в PubMed.
- Функция `get_abstracts_by_inn(inn)` формирует запрос `(INN[Title/Abstract]) AND (bioequivalence OR pharmacokinetics)`, получает PMID и загружает аннотации.

### 2.3. `inference_api.py`
- Реализует класс `LocalMedicalAI` для взаимодействия с локальной моделью Ollama через HTTP API.
- Метод `_check_api()` проверяет доступность сервера и наличие модели.
- Метод `_generate()` отправляет запрос с повторными попытками.
- `extract_pharmacokinetic_params()` формирует промпт для извлечения CVintra и T½ из аннотаций.
- `_get_fallback_params()` содержит базу знаний для популярных препаратов (используется при сбоях).
- `generate_rationale()` генерирует обоснование дизайна.

### 2.4. `sample_size.py`
- Реализует формулу расчёта размера выборки для 2x2 кроссовер-дизайна:
  \[
  N = \frac{2(Z_{\alpha} + Z_{\beta})^2 \sigma^2}{(\ln 0.8)^2}
  \]
  где \(\sigma^2 = \ln(1 + CV^2)\).
- Учитывает dropout.

### 2.5. `synopsis_generator.py`
- Загружает шаблон .docx с помощью `python-docx`.
- Заменяет плейсхолдеры вида `{{название_поля}}` на значения из словаря `data`.
- Сохраняет заполненный документ.

### 2.6. `main.py`
- Организует интерфейс Streamlit.
- Собирает входные параметры, вызывает модули, отображает результаты.
- Реализует логику fallback: если AI не вернул данные, предлагает ручной ввод.
- Формирует словарь `data` для заполнения шаблона.

## 3. Взаимодействие с PubMed
- Используется E-utilities с обязательным указанием email.
- Запрос ограничен 5 аннотациями для скорости.
- Текст аннотаций обрезается до 3000 символов (лимит контекста модели).

## 4. AI-компонент (Ollama)
- Модель `mistral` (7B) запускается локально.
- Общение через HTTP POST на `http://127.0.0.1:11434/api/generate`.
- Параметры: `temperature=0.1` (низкая для точности), `num_predict=512`.
- При ошибках подключения делается до 3 повторных попыток с экспоненциальной задержкой.

## 5. Расчёт выборки
- Мощность 80%, уровень значимости α=0.05 (двусторонний).
- Формула соответствует Решению №85 и примеру из кейса.
- Итоговое число округляется вверх, добавляется запас на dropout.

## 6. Генерация синопсиса
- Шаблон должен содержать уникальные плейсхолдеры, например `{{Название протокола}}`.
- Замена происходит во всех параграфах и ячейках таблиц.
- Сохраняется форматирование исходного шаблона.

## 7. Обработка ошибок и fallback
- Если сервер Ollama недоступен, флаг `api_available = False`, AI-методы возвращают `None`.
- При отсутствии извлечённых параметров пользователь видит поля для ручного ввода.
- Если аннотации не найдены, сразу используется база знаний.
- Все исключения логируются через `st.warning`/`st.error`.

## 8. Используемые библиотеки
- `streamlit` – веб-интерфейс
- `biopython` – работа с PubMed
- `python-docx` – генерация .docx
- `scipy`, `numpy` – статистические расчёты
- `requests` – HTTP-запросы к Ollama
- `pandas` – для работы с данными (опционально)

## 9. Возможные улучшения
- Добавление кэширования аннотаций для ускорения.
- Поддержка других моделей (Gemma, Llama).
- Расширение базы знаний до 50+ препаратов.
- Интеграция с DrugBank для более точных данных.
